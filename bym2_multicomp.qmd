---
title: Extending the BYM2 Model for Disconnected Graphs
format:
  html:
    css: theming/quarto_styles.css
    syntax-definitions:
      - theming/stan.xml
    embed-resources: true
    toc: true
    toc-location: left
    grid:
      body-width: 1000px
execute:
  eval: false
  keep-ipynb: true
jupyter: python3
---

```{python}
# import all libraries used in this notebook
import os
import numpy as np
import pandas as pd
import geopandas as gpd
import libpysal
import matplotlib as plt
import splot as splt
from splot.libpysal import plot_spatial_weights 
import plotnine as p9

from cmdstanpy import CmdStanModel

# suppress plotnine warnings
import warnings
warnings.filterwarnings('ignore')
# setup plotnine look and feel global
p9.theme_set(
  p9.theme_grey() + 
  p9.theme(text=p9.element_text(size=10),
        plot_title=p9.element_text(size=14),
        axis_title_x=p9.element_text(size=12),
        axis_title_y=p9.element_text(size=12),
        axis_text_x=p9.element_text(size=8),
        axis_text_y=p9.element_text(size=8)
       )
)

from utils_bym2 import get_scaling_factor
from utils_nyc_map import nyc_sort_by_comp_size
from utils_dataviz import *
```

**R**
```r
library(sf)
library(dplyr)
library(spdep)
source("utils_nyc_map.R")
```

## Assemble data

Data block of the Stan BYM2 model for disconnected components and islands:

```
  int<lower=0> N;
  array[N] int<lower=0> y; // count outcomes
  vector<lower=0>[N] E; // exposure
  int<lower=1> K; // num covariates
  matrix[N, K] xs; // design matrix

  // neighbor graph structure
  int<lower=0, upper=N> N_components;
  array[N_components] int<lower=1, upper=N> component_sizes;
  int<lower=0, upper=N> N_singletons;
  int<lower = 0> N_edges;  // number of neighbor pairs
  array[2, N_edges] int<lower = 1, upper = (N - N_singletons)> neighbors;  // columnwise adjacent
  vector<lower=0>[N_components] scaling_factors;
```

Get study data

```{python}
nyc_geodata = gpd.read_file(os.path.join('data', 'nyc_study.geojson'))
nyc_geodata.columns
```

Edit map as needed.

```{python}
nyc_nbs = libpysal.weights.Rook.from_dataframe(nyc_geodata, geom_col='geometry')
plot_spatial_weights(nyc_nbs, nyc_geodata)
```

Check dataframe, neighbors graph.

```{python}
(nyc_nbs, nyc_gdf, sizes) = nyc_sort_by_comp_size(nyc_geodata)
plot_spatial_weights(nyc_nbs, nyc_gdf)
```

```{python}
nyc_gdf[['NTAName', 'comp_id', 'comp_size']].head(4)
```

```{python}
nyc_gdf[['NTAName', 'comp_id', 'comp_size']].tail(4)
```

Assemble Poisson regression covariates.

```{python}
N = nyc_gdf.shape[0]
print("N", N)
y = nyc_gdf['count'].astype(int).tolist()
print("y", y[:7])
E = nyc_gdf['kid_pop'].astype(int).tolist()
print("E", E[:7])

x_cols = ['pct_pubtransit', 'med_hh_inc', 'traffic', 'frag_index']
K = len(x_cols)
print("K", K)
xs = nyc_gdf[x_cols].to_numpy()
### we need to standardize xs
xs[:, 1] = np.log(xs[:, 1])
xs[:, 2] = np.log(xs[:, 2])

print('xs', xs[:4, :])
pd.DataFrame(data=xs).describe()
```

```{python}
# compute number of components, sizes, and number of singleton nodes
print(sizes)
component_sizes = [x for x in sizes if x > 1]
N_components = len(component_sizes)
N_singletons = len(sizes) - N_components
print("N_components ", N_components, " N_singletons ", N_singletons, " component_sizes ", component_sizes)
print("N connected ", np.sum(component_sizes))
```

```{python}
# compute neighbors array
nbs_adj =  nyc_nbs.to_adjlist(remove_symmetric=True)
print(nbs_adj.head(4))
print(nbs_adj.tail(4))
# create np.ndarray from columns in adjlist, increment indices by 1
j1 = nbs_adj['focal'] + 1
j2 = nbs_adj['neighbor'] + 1
neighbors = np.vstack([j1, j2])
N_edges = neighbors.shape[1]
print("N_edges", N_edges)
print("start array cols\n", neighbors[:, :10])
print("end array cols\n", neighbors[:, -10:]) 
```

```{python}
# get scaling factors

rook_scaling_factors = np.ones(N_components)
for i in range(N_components):
    comp_gdf = nyc_gdf[nyc_gdf['comp_id'] == i].reset_index(drop=True)
    comp_nbs = libpysal.weights.Rook.from_dataframe(comp_gdf, geom_col='geometry')
    # plot_spatial_weights(comp_nbs, comp_gdf)
    component_w = libpysal.weights.W(comp_nbs.neighbors, comp_nbs.weights)
    rook_scaling_factors[i] = get_scaling_factor(component_w)

print(rook_scaling_factors)
```

```{python}
# assemble nyc_data_dict
nyc_data_dict = {
    'N':N,
    'y':y,
    'E':E,
    'K':K,
    'xs':xs,
    'N_components':N_components,
    'component_sizes': component_sizes,
    'N_singletons':N_singletons,
    'N_edges':N_edges,
    'neighbors':neighbors,
    'scaling_factors': rook_scaling_factors
}
```

## Fit model

```{python}
bym2_multicomp_mod = CmdStanModel(stan_file=os.path.join('stan', 'bym2_multicomp.stan'))
```

```{python}
#| scrolled: true
bym2_multicomp_fit = bym2_multicomp_mod.sample(data = nyc_data_dict, iter_warmup=3000, iter_sampling=2000)
```

```{python}
bym2_multicomp_fit.summary().head(8).round(2)
```


